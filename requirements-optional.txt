# Optional Dependencies for Advanced LLM Features
# ===============================================
# These dependencies are for advanced LLM capabilities including:
# - Local transformer models
# - Custom embeddings
# - Advanced vector search
# - GPU acceleration

# Install with: pip install -r requirements-optional.txt

# Transformer Models and PyTorch
# ==============================
transformers>=4.36.0  # For custom transformer models (BERT, GPT, etc.)
torch>=2.1.0  # For transformers - CPU version
# For GPU support with CUDA 11.8, use instead:
# torch>=2.1.0 --index-url https://download.pytorch.org/whl/cu118
# For GPU support with CUDA 12.1, use instead:
# torch>=2.1.0 --index-url https://download.pytorch.org/whl/cu121

# Additional Embeddings Support
# =============================
sentence-transformers>=2.2.0  # Already in main requirements, but listed for clarity

# Vector Search
# =============
faiss-cpu>=1.7.4  # For advanced vector search capabilities
# For GPU support, use instead:
# faiss-gpu>=1.7.4

# Additional ML Libraries
# ======================
scikit-learn>=1.3.0  # Already in main requirements, but listed for clarity

# Optional: Hugging Face Integration
# ==================================
huggingface-hub>=0.19.0  # For downloading models from Hugging Face
tokenizers>=0.15.0  # Fast tokenizers for transformers
datasets>=2.14.0  # For working with datasets
accelerate>=0.25.0  # For distributed training and inference

# Optional: Additional AI/ML Tools
# ================================
# spacy>=3.7.0  # For NLP pipelines
# nltk>=3.8.0  # Natural Language Toolkit
# gensim>=4.3.0  # Topic modeling and document similarity

# Optional: Optimization Tools
# ============================
# onnx>=1.15.0  # For model optimization
# onnxruntime>=1.16.0  # For optimized inference
# tensorrt>=8.6.0  # NVIDIA TensorRT for GPU optimization (requires CUDA)

# Note: Some of these packages have significant size and compilation requirements.
# Only install what you actually need for your use case.